CREATE OR REPLACE PROCEDURE ${aether_5g_core_module_tgt_dataset_name}.aether_smf_performance_sp(process_ts STRING,trans_ts STRING,window_hour int64,window_interval int64)
options(strict_mode=False)
BEGIN
  --Insert entry into audit table

SET @@query_label =  CONCAT('etl_type: bq_sp, task_name: bq-aether_smf_performance_sp, frequency:hourly, dataproduct: nw_perf, dataset_id: ${aether_5g_core_module_tgt_dataset_name}, table_id: ${aether_5g_core_module_tgt_smf_tblname}, schedule_time:', FORMAT_TIMESTAMP('%Y%m%d%H%M%S', TIMESTAMP(process_ts))); 

MERGE
  `${target_project_id}.${audit_tgt_dataset_name}.${audit_target_tblname}` tgt
USING
  (
  SELECT
    CONCAT("5g core smf hourly process") as prc_name,
    safe_cast(trans_ts AS datetime) AS start_time,
    safe_cast(SPLIT(trans_ts,' ')[
    OFFSET
      (0)] AS date) src_prc_dt ) src
ON ( src.prc_name=tgt.PROCESS_NAME AND src.START_TIME=tgt.START_TIME)
  WHEN NOT MATCHED THEN INSERT (
    PROCESS_MODULE,
    SCHEDULER,
    PROCESS_NAME,
    SOURCE_NAME,
    TARGET_NAME,
    START_TIME,
    END_TIME,
    PROCESS_DT,
    NUM_RECORDS_AFFECTED,
    STATUS,
    RETURN_MESSAGE )
  VALUES
  (
    "aether",
    "airflow",
    prc_name,
    "${aether_5g_core_module_src_project_id}.${aether_5g_core_module_src_dataset_name}.${aether_5g_core_module_src_smf_tblname}",
    "${aether_5g_core_module_tgt_project_id}.${aether_5g_core_module_tgt_dataset_name}.${aether_5g_core_module_tgt_smf_tblname}",
     start_time,
     NULL,
     src_prc_dt,
     NULL,
     "Started",
     NULL
      );

--==================================================================================================================================================================================
-- RAW DATA SCRAPE INTERVAL : Every 1 minute 
-- DATA AGGREGATION LEVEL   : 1- hour window 
-- trans_ts is always at 35th minute of the hour
--==================================================================================================================================================================================

merge into `${aether_5g_core_module_tgt_project_id}.${aether_5g_core_module_tgt_dataset_name}.${aether_5g_core_module_tgt_smf_tblname}` tgt
using (
---- Final SELECT from the CTE chain that calculates increase and sum value 
select
 event_time as event_time,
"ericsson" as  vendor,
fqdn,
labels,
KEY as metric_name,
safe_cast(increase_value as bignumeric) as metric_increase_value,
safe_cast(sum_value as bignumeric) as metric_sum_value,
safe_cast(p_90 as bignumeric) as metric_p_90_value,
safe_cast(sum_by_value as bignumeric) as metric_sum_by_value,
trans_dt,
datetime(process_ts) as schedule_time,
current_timestamp as updated_timestamp
from
(
WITH event_timestamps as
(
---- Generates a set of hourly timestamps based on insert_date_utc and trans_ts to handle delayed data
select distinct DATETIME_TRUNC(timestamp(`timestamp`),HOUR) as trans_hr from   vz-it-pr-gudv-dtwndo-0.aid_dtwin_core_uat_tbls.oracle_cnf_scp_raw_v1_temp
 ---- This includes not just the current hour, but also the past hours if their is any data delay
  where DATETIME_TRUNC(timestamp(insert_date_utc),HOUR)  in
  unnest(GENERATE_TIMESTAMP_ARRAY(TIMESTAMP_SUB(DATETIME_TRUNC(timestamp(trans_ts),HOUR),INTERVAL window_interval-1 HOUR),DATETIME_TRUNC(timestamp(trans_ts),HOUR),INTERVAL window_hour HOUR))
--    and trans_dt=date(timestamp(trans_ts))
   and trans_dt is not null-- need to check
)
,
  base_data AS (
  select *,
  MD5(labels) as checksum
  from (
---- Round timestamp down to the nearest hour bucket
  SELECT
  distinct
    TIMESTAMP_SECONDS(CAST(FLOOR(UNIX_SECONDS(`timestamp`)/(window_hour*60*60)) * (window_hour*60*60) AS INT64)) AS event_time,
    fqdn,
---- clean and normalize label JSON by removing unnecessary fields
   TO_JSON_STRING(JSON_REMOVE(SAFE.PARSE_JSON(labels),'$.__name__','$.jobid','$.job','$.localdn','$.instance','$.write_relabel_group','$.kubernetes_namespace','$.kubernetes_pod_name','$.pod_name','$.applicationId','$.icr_group')) as labels,
   JSON_VALUE(labels,'$.instance') as instance,
    lower(name) as KEY,
    SAFE_CAST(nullif(value,'NaN') AS FLOAT64) AS value,
    DATE(`timestamp`) AS trans_dt,
    `timestamp`,
  FROM
     vz-it-pr-gudv-dtwndo-0.aid_dtwin_core_uat_tbls.oracle_cnf_scp_raw_v1_temp
---- Filter data that belongs to the event window
    WHERE DATETIME_TRUNC(timestamp(`timestamp`),HOUR) in (select trans_hr from event_timestamps)
---- Consider only data inserted after the window start
    and insert_date_utc > (select min(trans_hr) from event_timestamps)
and trans_dt in (select date(trans_hr) from event_timestamps)
and trans_dt is not null
)
),
---- identify metric resets using lag function
window_data AS (
---- Check if value has reset comparing it to the previous value
select *,if(value<prev_value,1,0) has_reset,FIRST_VALUE(value) OVER (
        PARTITION BY trans_dt, event_time, fqdn,instance, checksum, KEY
        ORDER BY `timestamp` DESC
      ) AS sum_by_value from (
select
   trans_dt,
   event_time,
   fqdn,
   labels,
   checksum,
   instance,
   KEY,
   value,
   `timestamp`,
---- Apply lag logic to get previous value for each metric_name,fqdn, checksum and instance combination in case of reset and calculate increase value
   SAFE_CAST(LAG(value) OVER (PARTITION BY fqdn, instance, checksum, KEY, DATETIME_TRUNC(timestamp,HOUR) ORDER BY `timestamp`) AS FLOAT64) AS prev_value
from base_data
)
),
  reset_adjusted AS (
  SELECT
    event_time,
    fqdn,
    instance,
    trans_dt,
    MAX(labels) AS labels,
    checksum,
    KEY,
    sum(value) as sum_value,---- sum all the values over the hour
    SUM(CASE
        WHEN prev_value is NULL THEN 0 ---- skip first record of each partition
        WHEN has_reset =1 THEN value   ---- full value if reset occured
        ELSE value - IFNULL(prev_value,0)-- Difference otherwise
    END
      ) AS increase_value,
---- Approximate 90th percentile from the value distribution
    APPROX_QUANTILES(value, 100)[OFFSET(90)] as p_90,
    sum_by_value
  FROM
    window_data
  GROUP BY
   trans_dt,
   event_time,
   instance,
   fqdn,
   sum_by_value,
   checksum,
   KEY )
---- Aggregate instance level to get total increase/sum/p_90 value per metric and fqdn 
SELECT
  event_time,
  fqdn,
  trans_dt,
  SAFE.PARSE_JSON(labels)  AS labels,---- convert labels string back to JSON object
  checksum,
  KEY,
  increase_value,
  sum_value,
  p_90,
  sum_by_value
FROM (
  SELECT
  event_time,
  fqdn,
  trans_dt,
  labels,
  checksum,
  KEY,
---- Final aggregation for metrics
  SUM(increase_value) AS increase_value,
  SUM(sum_value) AS sum_value,
  sum(p_90) as p_90,
  sum(sum_by_value) as sum_by_value
FROM
  reset_adjusted
GROUP BY   
  event_time,
  fqdn,
  trans_dt,
  labels,  
  checksum,
  KEY
)
ORDER BY
  trans_dt,
  event_time,
  fqdn,
  checksum,
  KEY
  )
) src
on tgt.trans_dt=src.trans_dt
and tgt.event_time=src.event_time
and tgt.fqdn=src.fqdn
and tgt.metric_name=src.metric_name
and tgt.vendor=src.vendor
and MD5(to_json_string(tgt.labels))=MD5(to_json_string(src.labels))
and tgt.trans_dt is not null
  WHEN MATCHED
    THEN UPDATE SET
--    tgt.labels=src.labels, -- need clarification on this need to add in keys or update
    tgt.metric_increase_value=src.metric_increase_value,
    tgt.metric_sum_value=src.metric_sum_value,
    tgt.metric_p_90_value=src.metric_p_90_value,
    tgt.metric_sum_by_value=src.metric_sum_by_value,
    tgt.schedule_time=src.schedule_time,
    tgt.updated_timestamp=src.updated_timestamp
when not matched then
insert
(
event_time,
vendor,
fqdn,
labels,
metric_name,
metric_increase_value,
metric_sum_value,
metric_p_90_value,
metric_sum_by_value,
trans_dt,
schedule_time,
updated_timestamp
)
values(
src.event_time,
src.vendor,
src.fqdn,
src.labels,
src.metric_name,
src.metric_increase_value,
src.metric_sum_value,
src.metric_p_90_value,
src.metric_sum_by_value,
src.trans_dt,
src.schedule_time,
src.updated_timestamp
);

--update audit table with completed status
UPDATE
  `${target_project_id}.${audit_tgt_dataset_name}.${audit_target_tblname}`
SET
  END_TIME=CURRENT_DATETIME(),
  NUM_RECORDS_AFFECTED=@@ROW_COUNT,
  STATUS="Completed",
  RETURN_MESSAGE="Success"
WHERE
  PROCESS_NAME=CONCAT("5g core smf hourly process")
  AND start_time=safe_cast(trans_ts AS datetime);

SELECT
  "Process Completed Successfully"; 

EXCEPTION
WHEN ERROR THEN
  --update audit table with error status
UPDATE `${target_project_id}.${audit_tgt_dataset_name}.${audit_target_tblname}`
SET END_TIME=CURRENT_DATETIME(),
STATUS="Error",
RETURN_MESSAGE=CONCAT(@@error.message,'------***----',@@error.statement_text)
WHERE PROCESS_NAME=CONCAT("5g core smf hourly process") AND start_time=safe_cast(trans_ts AS datetime); RAISE USING message=@@error.message;
END;

